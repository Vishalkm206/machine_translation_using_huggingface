{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:35:27.310700Z","iopub.execute_input":"2025-03-27T06:35:27.311002Z","iopub.status.idle":"2025-03-27T06:35:27.528909Z","shell.execute_reply.started":"2025-03-27T06:35:27.310977Z","shell.execute_reply":"2025-03-27T06:35:27.527872Z"}},"outputs":[{"name":"stdout","text":"Thu Mar 27 06:35:27 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   40C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   40C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:35:27.530415Z","iopub.execute_input":"2025-03-27T06:35:27.530753Z","iopub.status.idle":"2025-03-27T06:35:35.799458Z","shell.execute_reply.started":"2025-03-27T06:35:27.530718Z","shell.execute_reply":"2025-03-27T06:35:35.798646Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip uninstall -y transformers accelerate\n!pip install transformers accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:35:35.800998Z","iopub.execute_input":"2025-03-27T06:35:35.801327Z","iopub.status.idle":"2025-03-27T06:35:48.609083Z","shell.execute_reply.started":"2025-03-27T06:35:35.801304Z","shell.execute_reply":"2025-03-27T06:35:48.608235Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.47.0\nUninstalling transformers-4.47.0:\n  Successfully uninstalled transformers-4.47.0\nFound existing installation: accelerate 1.2.1\nUninstalling accelerate-1.2.1:\n  Successfully uninstalled accelerate-1.2.1\nCollecting transformers\n  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\nCollecting accelerate\n  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.50.1-py3-none-any.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, accelerate\nSuccessfully installed accelerate-1.5.2 transformers-4.50.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Importing Libraries\n","metadata":{}},{"cell_type":"code","source":"import os\nimport sys \nimport transformers\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer,TFAutoModelForSeq2SeqLM,DataCollatorForSeq2Seq,AdamWeightDecay","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:35:48.610487Z","iopub.execute_input":"2025-03-27T06:35:48.610814Z","iopub.status.idle":"2025-03-27T06:36:10.874330Z","shell.execute_reply.started":"2025-03-27T06:35:48.610788Z","shell.execute_reply":"2025-03-27T06:36:10.873603Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Loading Dataset","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('cfilt/iitb-english-hindi')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:10.875118Z","iopub.execute_input":"2025-03-27T06:36:10.875744Z","iopub.status.idle":"2025-03-27T06:36:15.641452Z","shell.execute_reply.started":"2025-03-27T06:36:10.875720Z","shell.execute_reply":"2025-03-27T06:36:15.640587Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a356743ea9c404dad32c874dbea7ff8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62758eadeffd4a7aa9b684553ee80fde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/190M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b649cdc6fa904fa483bdeab1b2d9c4dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/85.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e16ae328b004685b1de01147dd8ce66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e25fffa4e0748da881ed3f213955c17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1659083 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c32d20131a040c99f0914c3a59c1c99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"736711ed1470458db8cf49570da7a31f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c370f3231114f41854eecae291b6233"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:15.642409Z","iopub.execute_input":"2025-03-27T06:36:15.642749Z","iopub.status.idle":"2025-03-27T06:36:15.648059Z","shell.execute_reply.started":"2025-03-27T06:36:15.642718Z","shell.execute_reply":"2025-03-27T06:36:15.647194Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 1659083\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 520\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2507\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"dataset['train'][:15]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:15.649031Z","iopub.execute_input":"2025-03-27T06:36:15.649378Z","iopub.status.idle":"2025-03-27T06:36:15.814721Z","shell.execute_reply.started":"2025-03-27T06:36:15.649346Z","shell.execute_reply":"2025-03-27T06:36:15.813934Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'translation': [{'en': 'Give your application an accessibility workout',\n   'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'},\n  {'en': 'Accerciser Accessibility Explorer',\n   'hi': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'},\n  {'en': 'The default plugin layout for the bottom panel',\n   'hi': 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका'},\n  {'en': 'The default plugin layout for the top panel',\n   'hi': 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका'},\n  {'en': 'A list of plugins that are disabled by default',\n   'hi': 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है'},\n  {'en': 'Highlight duration', 'hi': 'अवधि को हाइलाइट रकें'},\n  {'en': 'The duration of the highlight box when selecting accessible nodes',\n   'hi': 'पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि'},\n  {'en': 'Highlight border color',\n   'hi': 'सीमांत (बोर्डर) के रंग को हाइलाइट करें'},\n  {'en': 'The color and opacity of the highlight border.',\n   'hi': 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। '},\n  {'en': 'Highlight fill color', 'hi': 'भराई के रंग को हाइलाइट करें'},\n  {'en': 'The color and opacity of the highlight fill.',\n   'hi': 'हाइलाइट किया गया भराई का रंग और पारदर्शिता। '},\n  {'en': 'API Browser', 'hi': 'एपीआई विचरक'},\n  {'en': 'Browse the various methods of the current accessible',\n   'hi': 'इस समय जिसे प्राप्त किया गया हो, उसकी विभिन्न विधियों (मेथड) में विचरण करें'},\n  {'en': 'Hide private attributes', 'hi': 'निजी गुणों को छिपाएं'},\n  {'en': 'Method', 'hi': 'विधि'}]}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"model= 'Helsinki-NLP/opus-mt-en-hi'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:15.817090Z","iopub.execute_input":"2025-03-27T06:36:15.817305Z","iopub.status.idle":"2025-03-27T06:36:15.829068Z","shell.execute_reply.started":"2025-03-27T06:36:15.817287Z","shell.execute_reply":"2025-03-27T06:36:15.828162Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"tokenizer= AutoTokenizer.from_pretrained(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:15.830680Z","iopub.execute_input":"2025-03-27T06:36:15.830933Z","iopub.status.idle":"2025-03-27T06:36:17.800751Z","shell.execute_reply.started":"2025-03-27T06:36:15.830913Z","shell.execute_reply":"2025-03-27T06:36:17.799843Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc2318211c74410ab732b049f1a404db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85fcc3fc12b54b938bee09ee194090cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a7d4f317044b2eb933975e4150709b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f27d67349644a138aa5f11488b1d8e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2247d33b270742b392ff9f9afb62e55b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.801707Z","iopub.execute_input":"2025-03-27T06:36:17.802020Z","iopub.status.idle":"2025-03-27T06:36:17.808910Z","shell.execute_reply.started":"2025-03-27T06:36:17.801987Z","shell.execute_reply":"2025-03-27T06:36:17.807947Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-hi', vocab_size=61950, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t61949: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"tokenizer(\"My name is Vishal\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.810133Z","iopub.execute_input":"2025-03-27T06:36:17.810356Z","iopub.status.idle":"2025-03-27T06:36:17.827823Z","shell.execute_reply.started":"2025-03-27T06:36:17.810336Z","shell.execute_reply":"2025-03-27T06:36:17.827152Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [633, 300, 23, 3654, 5511, 916, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"tokenizer(['Hello My name is Vishal','I love to cook chicken today'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.828738Z","iopub.execute_input":"2025-03-27T06:36:17.829034Z","iopub.status.idle":"2025-03-27T06:36:17.843289Z","shell.execute_reply.started":"2025-03-27T06:36:17.829002Z","shell.execute_reply":"2025-03-27T06:36:17.842633Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[12110, 633, 300, 23, 3654, 5511, 916, 0], [56, 362, 7, 18814, 28985, 765, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"tokenizer(['Hello','My','name','is','Vishal'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.844085Z","iopub.execute_input":"2025-03-27T06:36:17.844368Z","iopub.status.idle":"2025-03-27T06:36:17.859137Z","shell.execute_reply.started":"2025-03-27T06:36:17.844336Z","shell.execute_reply":"2025-03-27T06:36:17.858223Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[12110, 0], [633, 0], [300, 0], [23, 0], [3654, 5511, 916, 0]], 'attention_mask': [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1, 1, 1]]}"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"tokenizer(['मेरा नाम विशाल है।'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.860013Z","iopub.execute_input":"2025-03-27T06:36:17.860317Z","iopub.status.idle":"2025-03-27T06:36:17.873517Z","shell.execute_reply.started":"2025-03-27T06:36:17.860286Z","shell.execute_reply":"2025-03-27T06:36:17.872809Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[44, 1056, 174, 428, 260, 44, 314, 260, 1056, 44, 1, 260, 800, 44, 1, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer(['मेरा नाम विशाल है।']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.874367Z","iopub.execute_input":"2025-03-27T06:36:17.874602Z","iopub.status.idle":"2025-03-27T06:36:17.889578Z","shell.execute_reply.started":"2025-03-27T06:36:17.874571Z","shell.execute_reply":"2025-03-27T06:36:17.888755Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [[500, 179, 7767, 5, 40, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.890416Z","iopub.execute_input":"2025-03-27T06:36:17.890684Z","iopub.status.idle":"2025-03-27T06:36:17.904013Z","shell.execute_reply.started":"2025-03-27T06:36:17.890651Z","shell.execute_reply":"2025-03-27T06:36:17.903371Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 1659083\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 520\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2507\n    })\n})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"def data_preprocess(sentense):\n    inputs = [ex['en'] for ex in sentense['translation']]\n    targets = [ex['hi'] for ex in sentense['translation']]\n\n    #tokenized inputs\n    encoded_inputs = tokenizer(inputs,max_length=128,truncation=True)\n\n    with tokenizer.as_target_tokenizer():\n        encoded_targets = tokenizer(targets,max_length=128,truncation=True)\n\n    encoded_inputs['labels'] = encoded_targets['input_ids']\n    return encoded_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.904900Z","iopub.execute_input":"2025-03-27T06:36:17.905169Z","iopub.status.idle":"2025-03-27T06:36:17.918994Z","shell.execute_reply.started":"2025-03-27T06:36:17.905138Z","shell.execute_reply":"2025-03-27T06:36:17.918119Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"tokenized_data = dataset.map(data_preprocess,batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:36:17.919831Z","iopub.execute_input":"2025-03-27T06:36:17.920072Z","iopub.status.idle":"2025-03-27T06:43:28.820665Z","shell.execute_reply.started":"2025-03-27T06:36:17.920053Z","shell.execute_reply":"2025-03-27T06:43:28.819890Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1659083 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e139427ea38456f81324e6720c9d0a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b1ae8e5433a4da89919ad01c5caea5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69033f7681134e28ac7858abfbc19cc4"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"tokenized_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:43:28.821477Z","iopub.execute_input":"2025-03-27T06:43:28.821774Z","iopub.status.idle":"2025-03-27T06:43:28.826687Z","shell.execute_reply.started":"2025-03-27T06:43:28.821751Z","shell.execute_reply":"2025-03-27T06:43:28.826029Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 1659083\n    })\n    validation: Dataset({\n        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 520\n    })\n    test: Dataset({\n        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2507\n    })\n})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model = TFAutoModelForSeq2SeqLM.from_pretrained(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:43:28.827365Z","iopub.execute_input":"2025-03-27T06:43:28.827548Z","iopub.status.idle":"2025-03-27T06:43:34.115855Z","shell.execute_reply.started":"2025-03-27T06:43:28.827531Z","shell.execute_reply":"2025-03-27T06:43:34.114893Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/306M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6358d68c12a044de8d565c9c14ffd5ab"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6413c3466b04693948779a2a8cedb11"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size=1\nlearning_rate=0.001\nweight_decay=0.01\nnum_train_epoch=10\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:43:34.116978Z","iopub.execute_input":"2025-03-27T06:43:34.117317Z","iopub.status.idle":"2025-03-27T06:43:34.121397Z","shell.execute_reply.started":"2025-03-27T06:43:34.117283Z","shell.execute_reply":"2025-03-27T06:43:34.120532Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer,model=model, return_tensors=\"tf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:43:34.122191Z","iopub.execute_input":"2025-03-27T06:43:34.122448Z","iopub.status.idle":"2025-03-27T06:43:34.136617Z","shell.execute_reply.started":"2025-03-27T06:43:34.122417Z","shell.execute_reply":"2025-03-27T06:43:34.135797Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"training_dataset = model.prepare_tf_dataset(\n    tokenized_data['test'],batch_size=batch_size,shuffle=True,collate_fn=data_collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:50:20.093898Z","iopub.execute_input":"2025-03-27T06:50:20.094226Z","iopub.status.idle":"2025-03-27T06:50:21.434625Z","shell.execute_reply.started":"2025-03-27T06:50:20.094178Z","shell.execute_reply":"2025-03-27T06:50:21.433919Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"validation_dataset = model.prepare_tf_dataset(\n    tokenized_data['validation'],\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:50:24.209932Z","iopub.execute_input":"2025-03-27T06:50:24.210247Z","iopub.status.idle":"2025-03-27T06:50:24.362575Z","shell.execute_reply.started":"2025-03-27T06:50:24.210223Z","shell.execute_reply":"2025-03-27T06:50:24.361946Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"optimizer=AdamWeightDecay(learning_rate,weight_decay)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:50:24.621554Z","iopub.execute_input":"2025-03-27T06:50:24.621784Z","iopub.status.idle":"2025-03-27T06:50:24.625081Z","shell.execute_reply.started":"2025-03-27T06:50:24.621764Z","shell.execute_reply":"2025-03-27T06:50:24.624407Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"model.compile(optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:50:26.442178Z","iopub.execute_input":"2025-03-27T06:50:26.442540Z","iopub.status.idle":"2025-03-27T06:50:26.458242Z","shell.execute_reply.started":"2025-03-27T06:50:26.442512Z","shell.execute_reply":"2025-03-27T06:50:26.457538Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:50:26.696982Z","iopub.execute_input":"2025-03-27T06:50:26.697219Z","iopub.status.idle":"2025-03-27T06:50:26.726975Z","shell.execute_reply.started":"2025-03-27T06:50:26.697180Z","shell.execute_reply":"2025-03-27T06:50:26.726424Z"}},"outputs":[{"name":"stdout","text":"Model: \"tf_marian_mt_model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n model (TFMarianMainLayer)   multiple                  76381184  \n                                                                 \n final_logits_bias (BiasLay  multiple                  61950     \n er)                                                             \n                                                                 \n=================================================================\nTotal params: 76443134 (291.61 MB)\nTrainable params: 76381184 (291.37 MB)\nNon-trainable params: 61950 (241.99 KB)\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"model.fit(training_dataset,validation_data=validation_dataset,epochs=num_train_epoch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:50:26.865151Z","iopub.execute_input":"2025-03-27T06:50:26.865436Z","iopub.status.idle":"2025-03-27T07:19:49.370287Z","shell.execute_reply.started":"2025-03-27T06:50:26.865403Z","shell.execute_reply":"2025-03-27T07:19:49.369417Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n2507/2507 [==============================] - 208s 72ms/step - loss: 7.5047 - val_loss: 7.6023\nEpoch 2/10\n2507/2507 [==============================] - 173s 69ms/step - loss: 7.1051 - val_loss: 7.3969\nEpoch 3/10\n2507/2507 [==============================] - 173s 69ms/step - loss: 6.9817 - val_loss: 7.4304\nEpoch 4/10\n2507/2507 [==============================] - 173s 69ms/step - loss: 6.9545 - val_loss: 7.5073\nEpoch 5/10\n2507/2507 [==============================] - 173s 69ms/step - loss: 6.9517 - val_loss: 7.5304\nEpoch 6/10\n2507/2507 [==============================] - 172s 69ms/step - loss: 6.9306 - val_loss: 7.5124\nEpoch 7/10\n2507/2507 [==============================] - 172s 69ms/step - loss: 6.9227 - val_loss: 7.5647\nEpoch 8/10\n2507/2507 [==============================] - 173s 69ms/step - loss: 6.9180 - val_loss: 7.5948\nEpoch 9/10\n2507/2507 [==============================] - 172s 69ms/step - loss: 6.9117 - val_loss: 7.5707\nEpoch 10/10\n2507/2507 [==============================] - 172s 69ms/step - loss: 6.9050 - val_loss: 7.6278\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7fa73a8d0d30>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"model.save_pretrained('/kaggle/working/model/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:24:09.239756Z","iopub.execute_input":"2025-03-27T07:24:09.240095Z","iopub.status.idle":"2025-03-27T07:24:10.490734Z","shell.execute_reply.started":"2025-03-27T07:24:09.240073Z","shell.execute_reply":"2025-03-27T07:24:10.489720Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]]}\n  warnings.warn(\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"input_text = \"Give your application an accessibility workout\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:24:14.246831Z","iopub.execute_input":"2025-03-27T07:24:14.247145Z","iopub.status.idle":"2025-03-27T07:24:14.250845Z","shell.execute_reply.started":"2025-03-27T07:24:14.247115Z","shell.execute_reply":"2025-03-27T07:24:14.249817Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"tokenized = tokenizer([input_text],return_tensors='np')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:24:15.270405Z","iopub.execute_input":"2025-03-27T07:24:15.270680Z","iopub.status.idle":"2025-03-27T07:24:15.274658Z","shell.execute_reply.started":"2025-03-27T07:24:15.270659Z","shell.execute_reply":"2025-03-27T07:24:15.273930Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"tokenized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:24:18.490413Z","iopub.execute_input":"2025-03-27T07:24:18.490713Z","iopub.status.idle":"2025-03-27T07:24:18.495934Z","shell.execute_reply.started":"2025-03-27T07:24:18.490691Z","shell.execute_reply":"2025-03-27T07:24:18.495089Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"{'input_ids': array([[ 3872,    85,  2501,   132, 15441, 36398,     0]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1]])}"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"out = model.generate(**tokenized,max_length=128).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:24:18.757957Z","iopub.execute_input":"2025-03-27T07:24:18.758162Z","iopub.status.idle":"2025-03-27T07:24:21.269341Z","shell.execute_reply.started":"2025-03-27T07:24:18.758143Z","shell.execute_reply":"2025-03-27T07:24:21.268655Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"with tokenizer.text_target():\n    print(tokenizer.decode(out[0],skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:25:03.497231Z","iopub.execute_input":"2025-03-27T07:25:03.497674Z","iopub.status.idle":"2025-03-27T07:25:03.811065Z","shell.execute_reply.started":"2025-03-27T07:25:03.497635Z","shell.execute_reply":"2025-03-27T07:25:03.809686Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-83029dfc02ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__} has no attribute {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: MarianTokenizer has no attribute text_target"],"ename":"AttributeError","evalue":"MarianTokenizer has no attribute text_target","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}